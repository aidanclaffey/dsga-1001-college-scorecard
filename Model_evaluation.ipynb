{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation for college scorecard - earnings prediction\n",
    "\n",
    "This notebook will use several different supervised learning regression algorithms to model earnings after college using College Scorecard data. The models included for evaluation will be:\n",
    "\n",
    "1. Linear Regression\n",
    "1. Decision Tree\n",
    "1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAIN</th>\n",
       "      <th>NUMBRANCH</th>\n",
       "      <th>ADM_RATE</th>\n",
       "      <th>PCIP01</th>\n",
       "      <th>PCIP03</th>\n",
       "      <th>PCIP04</th>\n",
       "      <th>PCIP05</th>\n",
       "      <th>PCIP09</th>\n",
       "      <th>PCIP10</th>\n",
       "      <th>PCIP11</th>\n",
       "      <th>...</th>\n",
       "      <th>CCSIZSET_17.0</th>\n",
       "      <th>CCSIZSET_nan</th>\n",
       "      <th>PFTFAC_ISNA</th>\n",
       "      <th>INEXPFTE_ISNA</th>\n",
       "      <th>AVGFACSAL_ISNA</th>\n",
       "      <th>GRAD_DEBT_MDN_ISNA</th>\n",
       "      <th>C150_4_ISNA</th>\n",
       "      <th>ADM_RATE_ISNA</th>\n",
       "      <th>TUITION_ISNA</th>\n",
       "      <th>TUITION_OUT_ISNT_IN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5575</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9117</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0574</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 267 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MAIN  NUMBRANCH  ADM_RATE  PCIP01  PCIP03  PCIP04  PCIP05  PCIP09  PCIP10  \\\n",
       "0     1        1.0    0.5575  0.0426  0.0019  0.0155  0.0000  0.0000   0.031   \n",
       "1     1        1.0    0.9117  0.0000  0.0000  0.0000  0.0006  0.0540   0.000   \n",
       "2     1        1.0    0.9050  0.0000  0.0000  0.0000  0.0000  0.0000   0.000   \n",
       "3     1        1.0    0.6931  0.0000  0.0000  0.0000  0.0000  0.0393   0.000   \n",
       "4     1        1.0    0.8462  0.0000  0.0000  0.0000  0.0041  0.1192   0.000   \n",
       "\n",
       "   PCIP11  ...  CCSIZSET_17.0  CCSIZSET_nan  PFTFAC_ISNA  INEXPFTE_ISNA  \\\n",
       "0  0.0756  ...              0             0            0              0   \n",
       "1  0.0276  ...              0             0            0              0   \n",
       "2  0.0574  ...              0             0            0              0   \n",
       "3  0.1253  ...              0             0            0              0   \n",
       "4  0.0164  ...              0             0            0              0   \n",
       "\n",
       "   AVGFACSAL_ISNA  GRAD_DEBT_MDN_ISNA  C150_4_ISNA  ADM_RATE_ISNA  \\\n",
       "0               0                   0            0              0   \n",
       "1               0                   0            0              0   \n",
       "2               0                   0            0              0   \n",
       "3               0                   0            0              0   \n",
       "4               0                   0            0              0   \n",
       "\n",
       "   TUITION_ISNA  TUITION_OUT_ISNT_IN  \n",
       "0             0                    1  \n",
       "1             0                    1  \n",
       "2             0                    1  \n",
       "3             0                    1  \n",
       "4             0                    1  \n",
       "\n",
       "[5 rows x 267 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "seed = 12345\n",
    "#load the data\n",
    "\n",
    "data = pd.read_pickle('clean_notna_data.pickle')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "name = X['INSTNM']\n",
    "X.drop('INSTNM', axis = 1, inplace = True)\n",
    "data = X.copy()\n",
    "data['Y'] = y\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "We need to split the data into training and test sets. Also, we need to think about possibly centering/normalizing the data.\n",
    "\n",
    "Normalizing may make sense at least for linear regression, so we can understand the features a little bit better\n",
    "\n",
    "Also, we can think about using PCA (if only for visualization purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test\n",
    "# Need to figure out best way to split time series data\n",
    "# Do we split based only on colleges (i.e. each college is either train or test)\n",
    "# Do we split based on college and year (i.e. each data entry is either train or test)\n",
    "# Another way to split?\n",
    "\n",
    "train_test_index = {0:'',1:'',2:'',3:'',4:'',5:''}\n",
    "for i in range(0,6):\n",
    "    train_test_index[i] = {\n",
    "        'train': X[X['YEAR'] <= i+2002].index,\n",
    "        'test' : X[X['YEAR'] == i + 2003].index\n",
    "    }\n",
    "X.drop('YEAR', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_val_index = list()\n",
    "train_val_dataset = list()\n",
    "for i in range(len(train_test_index)):\n",
    "    X_i = X.iloc[train_test_index[i]['train']]\n",
    "    y_i = y.iloc[train_test_index[i]['train']]\n",
    "    train_val_dataset.append(train_test_split(X_i,y_i,test_size = .2, random_state = seed))\n",
    "    train_val_index.append((train_val_dataset[i][0].index,train_val_dataset[i][1].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "First try: no feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of training set:  0.8354695882995418\n",
      "MSE of training set:  13975015.948902065\n",
      "RMSE of training set:  3738.3172616702914\n",
      "MAE of training set:  2675.3443939881936\n",
      "\n",
      "R^2 of validation set:  0.8171420557005532\n",
      "MSE of validation set:  14893159.98199828\n",
      "RMSE of validation set:  3859.165710616516\n",
      "MAE of validation set:  2843.6943177185126\n",
      "\n",
      "Coefficients:\n",
      "PCIP14 :  212045.018870773\n",
      "PCIP54 :  204349.27633699894\n",
      "PCIP29 :  197155.64544230278\n",
      "PCIP10 :  193362.7003692057\n",
      "PCIP46 :  191251.54628136917\n",
      "PCIP15 :  190445.83456037077\n",
      "PCIP47 :  190054.77813170548\n",
      "PCIP48 :  189296.36537719518\n",
      "PCIP52 :  187028.0943320917\n",
      "PCIP51 :  186942.04911731093\n",
      "PCIP11 :  186751.7580013466\n",
      "PCIP40 :  186633.7413034727\n",
      "PCIP41 :  184761.0342700867\n",
      "PCIP24 :  183182.7248339264\n",
      "PCIP22 :  182827.5252990272\n",
      "PCIP27 :  182712.77417633907\n",
      "PCIP16 :  182671.52385840903\n",
      "PCIP49 :  182616.41419035205\n",
      "PCIP31 :  182248.37746913123\n",
      "PCIP43 :  181264.37969528104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as m_s_e\n",
    "from sklearn.metrics import mean_absolute_error as m_a_e\n",
    "\n",
    "r2_array = {'train': list(), 'val': list()}\n",
    "mse_array = {'train': list(), 'val': list()}\n",
    "mae_array = {'train': list(), 'val': list()}\n",
    "\n",
    "linreg_coeffs = np.zeros_like(X.columns)\n",
    "for i in range(0,6):\n",
    "    X_train = X.loc[train_test_index[i]['train']]\n",
    "    y_train = y.iloc[train_test_index[i]['train']]\n",
    "    X_test = X.loc[train_test_index[i]['test']]\n",
    "    y_test = y.iloc[train_test_index[i]['test']]\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "\n",
    "    r2_array['train'].append(lin_reg.score(X_train, y_train))\n",
    "    mse_array['train'].append(m_s_e(y_train, lin_reg.predict(X_train)))\n",
    "    mae_array['train'].append(m_a_e(y_train, lin_reg.predict(X_train)))\n",
    "    \n",
    "    r2_array['val'].append(lin_reg.score(X_test, y_test))\n",
    "    mse_array['val'].append(m_s_e(y_test, lin_reg.predict(X_test)))\n",
    "    mae_array['val'].append(m_a_e(y_test, lin_reg.predict(X_test)))\n",
    "    \n",
    "    linreg_coeffs += lin_reg.coef_\n",
    "    \n",
    "linreg_coeffs /= 6\n",
    "print('R^2 of training set: ',np.mean(r2_array['train']))\n",
    "print('MSE of training set: ',np.mean(mse_array['train']))\n",
    "print('RMSE of training set: ', np.sqrt(np.mean(mse_array['train'])))\n",
    "print('MAE of training set: ',np.mean(mae_array['train']))\n",
    "print()\n",
    "print('R^2 of validation set: ',np.mean(r2_array['val']))\n",
    "print('MSE of validation set: ',np.mean(mse_array['val']))\n",
    "print('RMSE of validation set: ', np.sqrt(np.mean(mse_array['val'])))\n",
    "print('MAE of validation set: ',np.mean(mae_array['val']))\n",
    "print()\n",
    "print('Coefficients:')\n",
    "sorted_inds = np.argsort(-(np.abs(linreg_coeffs)))[:20]\n",
    "for i in sorted_inds:\n",
    "    print(X.columns[i], ': ', linreg_coeffs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second try: feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4c21df5bfc42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "r2_array = {'train': list(), 'val': list()}\n",
    "mse_array = {'train': list(), 'val': list()}\n",
    "mae_array = {'train': list(), 'val': list()}\n",
    "\n",
    "linreg_coeffs = np.zeros_like(X.columns)\n",
    "\n",
    "accuracy_array = {'train': list(), 'val': list()}\n",
    "for i in range(0,6):\n",
    "    X_train = X_scaled[train_test_index[i]['train']]\n",
    "    y_train = y[train_test_index[i]['train']]\n",
    "    X_test = X_scaled[train_test_index[i]['test']]\n",
    "    y_test = y[train_test_index[i]['test']]\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train, y_train)\n",
    "    \n",
    "    r2_array['train'].append(lin_reg.score(X_train, y_train))\n",
    "    mse_array['train'].append(m_s_e(y_train, lin_reg.predict(X_train)))\n",
    "    mae_array['train'].append(m_a_e(y_train, lin_reg.predict(X_train)))\n",
    "    \n",
    "    r2_array['val'].append(lin_reg.score(X_test, y_test))\n",
    "    mse_array['val'].append(m_s_e(y_test, lin_reg.predict(X_test)))\n",
    "    mae_array['val'].append(m_a_e(y_test, lin_reg.predict(X_test)))\n",
    "    \n",
    "    linreg_coeffs += lin_reg.coef_\n",
    "    \n",
    "linreg_coeffs /= 6\n",
    "print('R^2 of training set: ',np.mean(r2_array['train']))\n",
    "print('MSE of training set: ',np.mean(mse_array['train']))\n",
    "print('RMSE of training set: ', np.sqrt(np.mean(mse_array['train'])))\n",
    "print('MAE of training set: ',np.mean(mae_array['train']))\n",
    "print()\n",
    "print('R^2 of validation set: ',np.mean(r2_array['val']))\n",
    "print('MSE of validation set: ',np.mean(mse_array['val']))\n",
    "print('RMSE of validation set: ', np.sqrt(np.mean(mse_array['val'])))\n",
    "print('MAE of validation set: ',np.mean(mae_array['val']))\n",
    "print()\n",
    "print('Coefficients:')\n",
    "sorted_inds = np.argsort(-(np.abs(linreg_coeffs)))[:10]\n",
    "for i in sorted_inds:\n",
    "    print(X.columns[i], ': ', linreg_coeffs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First using out-of-box parameters (which will probably lead to overfitting)\n",
    "#use mse and then use mae\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "oob_array = list()\n",
    "r2_array = {'train': list(), 'val': list()}\n",
    "mse_array = {'train': list(), 'val': list()}\n",
    "mae_array = {'train': list(), 'val': list()}\n",
    "\n",
    "feature_importances = np.zeros_like(X.columns)\n",
    "for i in range(0,6):\n",
    "    X_train = X.loc[train_val_index[i][0]]\n",
    "    y_train = y.iloc[train_val_index[i][0]]\n",
    "    X_test = X.loc[train_val_index[i][1]]\n",
    "    y_test = y.iloc[train_val_index[i][1]]\n",
    "    rand_forest = RandomForestRegressor(criterion = 'mse',oob_score = True, random_state = seed,\n",
    "                                       n_estimators = 100)\n",
    "    rand_forest.fit(X_train, y_train)\n",
    "    \n",
    "    oob_array.append(rand_forest.oob_score_)\n",
    "    \n",
    "    r2_array['train'].append(rand_forest.score(X_train, y_train))\n",
    "    mse_array['train'].append(m_s_e(y_train, rand_forest.predict(X_train)))\n",
    "    mae_array['train'].append(m_a_e(y_train, rand_forest.predict(X_train)))\n",
    "    \n",
    "    r2_array['val'].append(rand_forest.score(X_test, y_test))\n",
    "    mse_array['val'].append(m_s_e(y_test, rand_forest.predict(X_test)))\n",
    "    mae_array['val'].append(m_a_e(y_test, rand_forest.predict(X_test)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    feature_importances += rand_forest.feature_importances_\n",
    "feature_importances /= 6\n",
    "\n",
    "print('OOB score : ', np.mean(oob_array))\n",
    "print('R^2 of training set: ',np.mean(r2_array['train']))\n",
    "print('MSE of training set: ',np.mean(mse_array['train']))\n",
    "print('RMSE of training set: ', np.sqrt(np.mean(mse_array['train'])))\n",
    "print('MAE of training set: ',np.mean(mae_array['train']))\n",
    "print()\n",
    "print('R^2 of validation set: ',np.mean(r2_array['val']))\n",
    "print('MSE of validation set: ',np.mean(mse_array['val']))\n",
    "print('RMSE of validation set: ', np.sqrt(np.mean(mse_array['val'])))\n",
    "print('MAE of validation set: ',np.mean(mae_array['val']))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(20)\n",
    "sorted_inds = np.argsort(-(feature_importances))[:20]\n",
    "sorted_colnames = X.columns[sorted_inds]\n",
    "fig = plt.figure(figsize = (15,5))\n",
    "plt.bar(x,feature_importances[sorted_inds], width = 0.8)\n",
    "plt.xticks(x,(sorted_colnames))\n",
    "plt.show()\n",
    "for i in range(0,20):\n",
    "    print(sorted_colnames[i],': ', feature_importances[sorted_inds[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 120\n",
    "max_features = [0.3,0.4,0.5,0.66,0.75,0.9,0.99, 1]\n",
    "\n",
    "# initialize accuracy dict which will have accuracy values for each run of the parameter tuning\n",
    "\n",
    "for max_f in max_features:\n",
    "    accuracy_dict[max_f] = {'r2':\n",
    "                                {'train':\n",
    "                                    {'list':list(),\n",
    "                                     'mean': 0},\n",
    "                                'test':\n",
    "                                    {'list':list(),\n",
    "                                     'mean': 0},\n",
    "                                'oob':\n",
    "                                    {'list':list(),\n",
    "                                     'mean': 0}},\n",
    "                            'mse':\n",
    "                                {'train':\n",
    "                                    {'list':list(),\n",
    "                                     'mean': 0},\n",
    "                                'test':\n",
    "                                    {'list':list(),\n",
    "                                     'mean': 0},\n",
    "                                'oob':\n",
    "                                    {'list':list(),\n",
    "                                     'mean': 0}},\n",
    "                            'mae':\n",
    "                                {'train':\n",
    "                                    {'list':list(),\n",
    "                                     'mean': 0},\n",
    "                                'test':\n",
    "                                    {'list':list(),\n",
    "                                     'mean': 0},\n",
    "                                'oob':\n",
    "                                    {'list':list(),\n",
    "                                     'mean': 0}}}\n",
    "\n",
    "for max_f in max_features:\n",
    "    for i in range(0,6):\n",
    "        X_train = X.loc[train_test_index[i]['train']]\n",
    "        y_train = y.iloc[train_test_index[i]['train']]\n",
    "        X_test = X.loc[train_test_index[i]['test']]\n",
    "        y_test = y.iloc[train_test_index[i]['test']]\n",
    "        rand_forest = RandomForestRegressor(n_estimators = n_estimators, max_features = max_f,\n",
    "                                        criterion = 'mse', oob_score = True, random_state = seed)\n",
    "        rand_forest.fit(X_train, y_train)\n",
    "\n",
    "        accuracy_dict[max_f]['r2']['oob']['list'].append(rand_forest.oob_score_)\n",
    "        accuracy_dict[max_f]['mse']['oob']['list'].append(m_s_e(y_train, rand_forest.oob_prediction_))\n",
    "        accuracy_dict[max_f]['mae']['oob']['list'].append(m_a_e(y_train, rand_forest.oob_prediction_))\n",
    "        \n",
    "        accuracy_dict[max_f]['r2']['train']['list'].append(rand_forest.score(X_train, y_train))\n",
    "        accuracy_dict[max_f]['mse']['train']['list'].append(m_s_e(y_train, rand_forest.predict(X_train)))\n",
    "        accuracy_dict[max_f]['mae']['train']['list'].append(m_a_e(y_train, rand_forest.predict(X_train)))\n",
    "        \n",
    "        accuracy_dict[max_f]['r2']['test']['list'].append(rand_forest.score(X_test, y_test))\n",
    "        accuracy_dict[max_f]['mse']['test']['list'].append(m_s_e(y_test, rand_forest.predict(X_test)))\n",
    "        accuracy_dict[max_f]['mae']['test']['list'].append(m_a_e(y_test, rand_forest.predict(X_test)))\n",
    "    \n",
    "    \n",
    "    accuracy_dict[max_f]['r2']['oob']['mean'] = np.mean(accuracy_dict[max_f]['r2']['oob']['list'])\n",
    "    accuracy_dict[max_f]['mse']['oob']['mean'] = np.mean(accuracy_dict[max_f]['mse']['oob']['list'])\n",
    "    accuracy_dict[max_f]['mae']['oob']['mean'] = np.mean(accuracy_dict[max_f]['mae']['oob']['list'])\n",
    "    \n",
    "    accuracy_dict[max_f]['r2']['train']['mean'] = np.mean(accuracy_dict[max_f]['r2']['train']['list'])\n",
    "    accuracy_dict[max_f]['mse']['train']['mean'] = np.mean(accuracy_dict[max_f]['mse']['train']['list'])\n",
    "    accuracy_dict[max_f]['mae']['train']['mean'] = np.mean(accuracy_dict[max_f]['mae']['train']['list'])\n",
    "                            \n",
    "    accuracy_dict[max_f]['r2']['test']['mean'] = np.mean(accuracy_dict[max_f]['r2']['test']['list'])\n",
    "    accuracy_dict[max_f]['mse']['test']['mean'] = np.mean(accuracy_dict[max_f]['mse']['test']['list'])\n",
    "    accuracy_dict[max_f]['mae']['test']['mean'] = np.mean(accuracy_dict[max_f]['mae']['test']['list'])\n",
    "    print(max_f)\n",
    "                            \n",
    "#change other parameters as we see fit (probably max_depth, min_size_leaf, min_size_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_pairs = list()\n",
    "groups = ['oob', 'train', 'test']\n",
    "metrics = ['r2', 'rmse', 'mae']\n",
    "for group in groups:\n",
    "    for metric in metrics:\n",
    "        column_pairs.append((group, metric))\n",
    "\n",
    "micolumns = pd.MultiIndex.from_tuples(column_pairs)\n",
    "\n",
    "accuracy_means = pd.DataFrame(columns = micolumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_f in max_features:\n",
    "    oob_r2 = accuracy_dict[max_f]['r2']['oob']['mean']\n",
    "    oob_mse = accuracy_dict[max_f]['mse']['oob']['mean']\n",
    "    oob_rmse = np.sqrt(oob_mse)\n",
    "    oob_mae = accuracy_dict[max_f]['mae']['oob']['mean']\n",
    "    \n",
    "    train_r2 = accuracy_dict[max_f]['r2']['train']['mean']\n",
    "    train_mse = accuracy_dict[max_f]['mse']['train']['mean']\n",
    "    train_rmse = np.sqrt(train_mse)\n",
    "    train_mae = accuracy_dict[max_f]['mae']['train']['mean']\n",
    "    \n",
    "    test_r2 = accuracy_dict[max_f]['r2']['test']['mean']\n",
    "    test_mse = accuracy_dict[max_f]['mse']['test']['mean']\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    test_mae = accuracy_dict[max_f]['mae']['test']['mean']\n",
    "    \n",
    "    accuracy_means.loc[max_f] = [oob_r2, oob_rmse, oob_mae,train_r2,train_rmse,train_mae,\n",
    "                                 test_r2,test_rmse,test_mae]\n",
    "accuracy_means.sort_index(inplace = True)\n",
    "accuracy_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize =(16,4))\n",
    "ax1.plot(accuracy_means.index, accuracy_means['oob', 'r2'])\n",
    "ax1.title.set_text('OOB - R^2')\n",
    "ax1.set_xlabel('max features')\n",
    "ax2.plot(accuracy_means.index, accuracy_means['oob', 'rmse'])\n",
    "ax2.title.set_text('OOB -  Square Root MSE')\n",
    "ax2.set_xlabel('max features')\n",
    "ax3.plot(accuracy_means.index, accuracy_means['oob', 'mae'])\n",
    "ax3.title.set_text('OOB - MAE')\n",
    "ax3.set_xlabel('max features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using optimal max_features to find feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_max_f = 0.5\n",
    "\n",
    "r2_array = {'train': list(), 'test': list()}\n",
    "mse_array = {'train': list(), 'test': list()}\n",
    "mae_array = {'train': list(), 'test': list()}\n",
    "\n",
    "feature_importances = np.zeros_like(X.columns)\n",
    "for i in range(0,6):\n",
    "    X_train = X.loc[train_test_index[i]['train']]\n",
    "    y_train = y.iloc[train_test_index[i]['train']]\n",
    "    X_test = X.loc[train_test_index[i]['test']]\n",
    "    y_test = y.iloc[train_test_index[i]['test']]\n",
    "    rand_forest = RandomForestRegressor(criterion = 'mse',oob_score = True, max_features = best_max_f,\n",
    "                                        random_state = seed, n_estimators = 100)\n",
    "    rand_forest.fit(X_train, y_train)\n",
    "    \n",
    "    oob_array.append(rand_forest.oob_score_)\n",
    "    \n",
    "    r2_array['train'].append(rand_forest.score(X_train, y_train))\n",
    "    mse_array['train'].append(m_s_e(y_train, rand_forest.predict(X_train)))\n",
    "    mae_array['train'].append(m_a_e(y_train, rand_forest.predict(X_train)))\n",
    "    \n",
    "    r2_array['test'].append(rand_forest.score(X_test, y_test))\n",
    "    mse_array['test'].append(m_s_e(y_test, rand_forest.predict(X_test)))\n",
    "    mae_array['test'].append(m_a_e(y_test, rand_forest.predict(X_test)))\n",
    "    \n",
    "    feature_importances += rand_forest.feature_importances_\n",
    "feature_importances /= 6\n",
    "\n",
    "print('OOB score : ', np.mean(oob_array))\n",
    "print('R^2 of training set: ',np.mean(r2_array['train']))\n",
    "print('MSE of training set: ',np.mean(mse_array['train']))\n",
    "print('RMSE of training set: ', np.sqrt(np.mean(mse_array['train'])))\n",
    "print('MAE of training set: ',np.mean(mae_array['train']))\n",
    "print()\n",
    "print('R^2 of Test set: ',np.mean(r2_array['test']))\n",
    "print('MSE of Test set: ',np.mean(mse_array['test']))\n",
    "print('RMSE of Test set: ', np.sqrt(np.mean(mse_array['test'])))\n",
    "print('MAE of Test set: ',np.mean(mae_array['test']))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(20)\n",
    "sorted_inds = np.argsort(-(feature_importances))[:20]\n",
    "sorted_colnames = X.columns[sorted_inds]\n",
    "fig = plt.figure(figsize = (15,5))\n",
    "plt.bar(x,feature_importances[sorted_inds], width = 0.8)\n",
    "plt.xticks(x,(sorted_colnames))\n",
    "plt.show()\n",
    "for i in range(0,20):\n",
    "    print(sorted_colnames[i],': ', feature_importances[sorted_inds[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Least accurate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rand_forest.predict(X_test)\n",
    "diff = y_test - prediction\n",
    "absdiff = np.abs(prediction - y_test)\n",
    "sorted_inds = np.argsort(-(absdiff))[:10]\n",
    "\n",
    "for i in sorted_inds:\n",
    "    name_index = train_test_index[5]['test'][i]\n",
    "    print(name[name_index])\n",
    "    print('predicted value:\\t',prediction[i])\n",
    "    print('real value:\\t\\t', y_test[name_index])\n",
    "    print('difference:\\t\\t', diff[name_index])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most accurate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rand_forest.predict(X_test)\n",
    "diff = y_test - prediction\n",
    "absdiff = np.abs(prediction - y_test)\n",
    "sorted_inds = np.argsort(absdiff)[:10]\n",
    "\n",
    "for i in sorted_inds:\n",
    "    name_index = train_test_index[5]['test'][i]\n",
    "    print(name[name_index])\n",
    "    print(prediction[i])\n",
    "    print(y_test[name_index])\n",
    "    print(diff[name_index])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
